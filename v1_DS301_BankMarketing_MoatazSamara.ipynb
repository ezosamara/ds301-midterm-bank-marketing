{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezosamara/ds301-midterm-bank-marketing/blob/main/v1_DS301_BankMarketing_MoatazSamara.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3e44e54",
      "metadata": {
        "id": "f3e44e54"
      },
      "source": [
        "# DS 301 - Mid-Term Project  \n",
        "## Bank Marketing Classification\n",
        "\n",
        "**Student:** Moataz Samara, Samantha Acosta Valdez\n",
        "**Course:** DS 301 - Machine Learning Techniques  \n",
        "\n",
        "**Research Paper (Base):**  \n",
        "A Data-Driven Approach to Predict the Success of Bank Telemarketing  \n",
        "(Moro, Cortez, Rita)\n",
        "\n",
        "---\n",
        "\n",
        "### Project Goal\n",
        "\n",
        "We want to predict whether a bank client will subscribe to a term deposit (y = yes / no) before making the telemarketing call.\n",
        "\n",
        "In this project we:\n",
        "\n",
        "- Use the Bank Marketing dataset (bank-full.csv).\n",
        "- Implement and compare two classification models:\n",
        "  - Logistic Regression (LR)\n",
        "  - Decision Tree (DT)\n",
        "- Apply:\n",
        "  - Data preprocessing and feature engineering.\n",
        "  - Proper train/test split.\n",
        "  - Evaluation with accuracy, precision, recall, F1-score, and ROC-AUC.\n",
        "- Follow the idea of the research paper:\n",
        "  - Use only features known before the call → drop duration.\n",
        "  - Handle imbalanced data (few \"yes\" cases).\n",
        "\n",
        "We do not implement Neural Networks here, but we mention them in the conclusion as a possible improvement (they are used in the original paper)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67db517d",
      "metadata": {
        "id": "67db517d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
        "plt.rcParams[\"axes.grid\"] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c14aa05",
      "metadata": {
        "id": "4c14aa05"
      },
      "source": [
        "## 1. Load the Dataset\n",
        "\n",
        "We use the Bank Marketing dataset ('bank-full.csv'), which contains the result of multiple direct marketing campaigns by a Portuguese bank.\n",
        "\n",
        "- Each row = one client.\n",
        "- Target = 'y' → did the client subscribe to a term deposit? ('yes' / 'no')\n",
        "- Input features = client information, previous campaign outcomes, etc.\n",
        "\n",
        "We assume 'bank-full.csv' is in the same folder as this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6180f9ba",
      "metadata": {
        "id": "6180f9ba"
      },
      "outputs": [],
      "source": [
        "# Change the path if your file is in a \"data\" folder, e.g. \"data/bank-full.csv\"\n",
        "file_path = \"bank-full.csv\"\n",
        "\n",
        "bank = pd.read_csv(file_path, sep=';')\n",
        "\n",
        "# Show first 5 rows\n",
        "bank.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7764507",
      "metadata": {
        "id": "f7764507"
      },
      "source": [
        "## 2. Initial Data Understanding\n",
        "\n",
        "In this section we:\n",
        "- Look at the shape and column names.\n",
        "- Check the target variable distribution.\n",
        "- Inspect data types and missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35db7f89",
      "metadata": {
        "id": "35db7f89"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of the dataset:\", bank.shape)\n",
        "print(\"\\nColumns:\")\n",
        "print(bank.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95e6189",
      "metadata": {
        "id": "d95e6189"
      },
      "outputs": [],
      "source": [
        "print(\"Target variable (y) distribution:\")\n",
        "print(bank[\"y\"].value_counts())\n",
        "print(\"\\nTarget variable (y) distribution (percentage):\")\n",
        "print(bank[\"y\"].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "057acd4a",
      "metadata": {
        "id": "057acd4a"
      },
      "outputs": [],
      "source": [
        "bank.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52f78142",
      "metadata": {
        "id": "52f78142"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "According to the research paper, **call duration** (`duration`) is not used as a predictor, because:\n",
        "\n",
        "> Duration is only known *after* the call is finished.\n",
        "\n",
        "So we:\n",
        "1. **Drop `duration`**.\n",
        "2. **Encode the target `y`**:\n",
        "   - `no` → 0  \n",
        "   - `yes` → 1\n",
        "3. Separate:\n",
        "   - Features `X`\n",
        "   - Target `y`\n",
        "4. Identify **numeric** and **categorical** feature columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c69a863f",
      "metadata": {
        "id": "c69a863f"
      },
      "outputs": [],
      "source": [
        "# Copy to avoid editing the original dataframe directly\n",
        "df = bank.copy()\n",
        "\n",
        "# 1) Drop 'duration' (only known after the call)\n",
        "if \"duration\" in df.columns:\n",
        "    df = df.drop(columns=[\"duration\"])\n",
        "\n",
        "# 2) Encode target: 'no' -> 0, 'yes' -> 1\n",
        "df[\"y\"] = df[\"y\"].map({\"no\": 0, \"yes\": 1})\n",
        "\n",
        "print(\"Encoded target distribution:\")\n",
        "print(df[\"y\"].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f071815",
      "metadata": {
        "id": "9f071815"
      },
      "outputs": [],
      "source": [
        "# 3) Separate features and target\n",
        "X = df.drop(columns=[\"y\"])\n",
        "y = df[\"y\"]\n",
        "\n",
        "# 4) Identify numeric and categorical columns\n",
        "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "print(\"Numeric features:\", numeric_features)\n",
        "print(\"Categorical features:\", categorical_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96e70246",
      "metadata": {
        "id": "96e70246"
      },
      "source": [
        "## 4. Train–Test Split\n",
        "\n",
        "We split the data into:\n",
        "\n",
        "- **Training set:** 70%\n",
        "- **Test set:** 30%\n",
        "\n",
        "We use **stratified sampling** to keep the same proportion of \"yes\"/\"no\" in both sets. This is important because the data is **imbalanced** (much more \"no\" than \"yes\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4b2dc8",
      "metadata": {
        "id": "bf4b2dc8"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    stratify=y,       # keep class distribution similar\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Test size :\", len(X_test))\n",
        "print(\"Train positive rate (y=1):\", y_train.mean())\n",
        "print(\"Test positive rate  (y=1):\", y_test.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c022b0d",
      "metadata": {
        "id": "0c022b0d"
      },
      "source": [
        "## 5. Preprocessing Pipeline\n",
        "\n",
        "We build a **single preprocessing pipeline** which will be reused for both models:\n",
        "\n",
        "- For **numeric features**:\n",
        "  - `StandardScaler` → scales features to have mean 0 and standard deviation 1.  \n",
        "    This helps models like Logistic Regression.\n",
        "\n",
        "- For **categorical features**:\n",
        "  - `OneHotEncoder` → converts categories into binary columns (0/1).\n",
        "  - `handle_unknown=\"ignore\"` → avoids errors if new category appears in test data.\n",
        "\n",
        "We use `ColumnTransformer` to apply the correct transformation to each column group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b21ddb2",
      "metadata": {
        "id": "6b21ddb2"
      },
      "outputs": [],
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01d258a5",
      "metadata": {
        "id": "01d258a5"
      },
      "source": [
        "## 6. Helper: Training and Evaluation Function\n",
        "\n",
        "To avoid repeating code, we create a function that:\n",
        "\n",
        "1. Builds a **pipeline**: `preprocessor` → `model`.\n",
        "2. Fits the model on the training data.\n",
        "3. Predicts on the test data.\n",
        "4. Prints:\n",
        "   - Accuracy\n",
        "   - Precision\n",
        "   - Recall\n",
        "   - F1-score\n",
        "   - ROC-AUC\n",
        "   - Classification report\n",
        "5. Plots:\n",
        "   - Confusion Matrix\n",
        "   - ROC Curve\n",
        "\n",
        "We will use this for **both** Logistic Regression and Decision Tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e45ff9d4",
      "metadata": {
        "id": "e45ff9d4"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, model_name):\n",
        "    \"\"\"\n",
        "    Fit a pipeline (preprocessing + model),\n",
        "    print metrics, and return the fitted pipeline, probabilities and ROC-AUC.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Full pipeline: preprocessing + model\n",
        "    pipe = Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"model\", model)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Fit the model\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    y_prob = pipe.predict_proba(X_test)[:, 1]  # prob. for class 1 (y = 1)\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    print(f\"Accuracy     : {acc:.4f}\")\n",
        "    print(f\"Precision    : {prec:.4f}\")\n",
        "    print(f\"Recall       : {rec:.4f}\")\n",
        "    print(f\"F1-score     : {f1:.4f}\")\n",
        "    print(f\"ROC-AUC      : {roc_auc:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification report:\\n\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"no\", \"yes\"])\n",
        "    disp.plot(values_format=\"d\")\n",
        "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "    plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.3f})\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"ROC Curve - {model_name}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return pipe, y_prob, roc_auc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "936661c6",
      "metadata": {
        "id": "936661c6"
      },
      "source": [
        "## 7. Model 1 – Logistic Regression\n",
        "\n",
        "**Why Logistic Regression?**\n",
        "\n",
        "- Simple and powerful baseline model.\n",
        "- Outputs **probabilities**, easy to interpret.\n",
        "- Works well with **scaled numeric variables** and one-hot encoded categories.\n",
        "\n",
        "We also use:\n",
        "\n",
        "- `class_weight=\"balanced\"` to help with class imbalance.\n",
        "- `max_iter=1000` to give the solver enough iterations to converge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5787c35d",
      "metadata": {
        "id": "5787c35d"
      },
      "outputs": [],
      "source": [
        "log_reg = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    class_weight=\"balanced\",\n",
        "    solver=\"lbfgs\"\n",
        ")\n",
        "\n",
        "lr_model, lr_prob, lr_auc = train_and_evaluate(log_reg, \"Logistic Regression\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3e6d6b",
      "metadata": {
        "id": "fc3e6d6b"
      },
      "source": [
        "## 8. Model 2 – Decision Tree\n",
        "\n",
        "**Why Decision Tree?**\n",
        "\n",
        "- Can model **non-linear relationships**.\n",
        "- Very **interpretable**: can be explained with IF/ELSE rules.\n",
        "- But:\n",
        "  - Can easily **overfit** if too deep.\n",
        "  - Needs regularization (max depth, min samples split, etc.) for production.\n",
        "\n",
        "Here we start with a basic tree and use `class_weight=\"balanced\"` to pay more attention to the minority class (`y = 1`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a00811",
      "metadata": {
        "id": "e1a00811"
      },
      "outputs": [],
      "source": [
        "dt_clf = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "\n",
        "dt_model, dt_prob, dt_auc = train_and_evaluate(dt_clf, \"Decision Tree\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8865f167",
      "metadata": {
        "id": "8865f167"
      },
      "source": [
        "## 9. Model Comparison\n",
        "\n",
        "We compare the two models using **ROC-AUC** on the test set:\n",
        "\n",
        "- Higher ROC-AUC = better ability to separate \"yes\" and \"no\".\n",
        "- We also look at accuracy, precision, recall, and F1-score in the previous cells.\n",
        "\n",
        "Here we build a small summary table and plot a bar chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c7db7e",
      "metadata": {
        "id": "e7c7db7e"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"Logistic Regression\", \"Decision Tree\"],\n",
        "    \"ROC_AUC\": [lr_auc, dt_auc]\n",
        "})\n",
        "\n",
        "results = results.sort_values(by=\"ROC_AUC\", ascending=False).reset_index(drop=True)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a58aa3",
      "metadata": {
        "id": "06a58aa3"
      },
      "outputs": [],
      "source": [
        "plt.bar(results[\"Model\"], results[\"ROC_AUC\"])\n",
        "plt.ylabel(\"ROC-AUC\")\n",
        "plt.title(\"Model Comparison (ROC-AUC)\")\n",
        "plt.ylim(0.5, 1.0)\n",
        "\n",
        "for i, v in enumerate(results[\"ROC_AUC\"]):\n",
        "    plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "030c80da",
      "metadata": {
        "id": "030c80da"
      },
      "source": [
        "## 10. (Optional) Lift Curve – Marketing View\n",
        "\n",
        "In marketing, we want to know:\n",
        "\n",
        "> If we contact only the **top X%** of clients (based on model score), what **percentage of all positive responses** (subscribers) do we capture?\n",
        "\n",
        "This is shown by a **Lift / Cumulative Response curve**.\n",
        "\n",
        "Below, we plot a simple version of this curve for the **better model** (usually Logistic Regression on this dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a794910e",
      "metadata": {
        "id": "a794910e"
      },
      "outputs": [],
      "source": [
        "def plot_lift_curve(y_true, y_scores, model_name):\n",
        "    # Combine true labels and predicted scores\n",
        "    df_lift = pd.DataFrame({\"y_true\": y_true, \"score\": y_scores})\n",
        "    # Sort by score (descending)\n",
        "    df_lift = df_lift.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Cumulative positives\n",
        "    df_lift[\"cum_positives\"] = df_lift[\"y_true\"].cumsum()\n",
        "    total_positives = df_lift[\"y_true\"].sum()\n",
        "\n",
        "    # Percentage of samples and positives\n",
        "    df_lift[\"perc_samples\"] = (np.arange(len(df_lift)) + 1) / len(df_lift)\n",
        "    df_lift[\"perc_positives\"] = df_lift[\"cum_positives\"] / total_positives\n",
        "\n",
        "    # Plot\n",
        "    plt.plot(df_lift[\"perc_samples\"], df_lift[\"perc_positives\"], label=model_name)\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random\")\n",
        "    plt.xlabel(\"Percentage of contacted clients\")\n",
        "    plt.ylabel(\"Percentage of subscribers captured\")\n",
        "    plt.title(f\"Lift (Cumulative Response) Curve - {model_name}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6541396e",
      "metadata": {
        "id": "6541396e"
      },
      "outputs": [],
      "source": [
        "# Use the best model (replace lr_prob with dt_prob if DT is better)\n",
        "best_model_name = \"Logistic Regression\"\n",
        "plot_lift_curve(y_test.values, lr_prob, best_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee1837f2",
      "metadata": {
        "id": "ee1837f2"
      },
      "source": [
        "## 11. Final Summary and Suggested Improvements\n",
        "\n",
        "### Problem Recap\n",
        "\n",
        "- **Goal:** Predict if a client will subscribe to a term deposit (`y = 1`) *before* calling them.\n",
        "- **Dataset:** `bank-full.csv` (Bank Marketing dataset).\n",
        "- **Target:** `y` (0 = no, 1 = yes).\n",
        "- **Important choice:** We dropped `duration` because it is only known *after* the call.\n",
        "\n",
        "### Models Implemented\n",
        "\n",
        "1. **Logistic Regression**\n",
        "   - Linear model.\n",
        "   - Works well with scaled numeric features and one-hot encoded categorical features.\n",
        "   - Produces interpretable coefficients and probability outputs.\n",
        "\n",
        "2. **Decision Tree**\n",
        "   - Non-linear model.\n",
        "   - Easy to explain to business users (rules).\n",
        "   - Can overfit if not properly regularized.\n",
        "\n",
        "### Evaluation\n",
        "\n",
        "- Train/Test Split: 70% / 30% (stratified).\n",
        "- Main metrics:\n",
        "  - Accuracy\n",
        "  - Precision\n",
        "  - Recall\n",
        "  - F1-score\n",
        "  - **ROC-AUC** (main comparison metric)\n",
        "\n",
        "### Results (fill with your values)\n",
        "\n",
        "- Logistic Regression: ROC-AUC ≈ **X.XXX**\n",
        "- Decision Tree:      ROC-AUC ≈ **Y.YYY**\n",
        "\n",
        "**Best model:** `<Write here which model performed better on ROC-AUC and why you prefer it>`\n",
        "\n",
        "### Relation to the Research Paper\n",
        "\n",
        "- We followed the same **problem**: predicting term deposit subscription.\n",
        "- We used similar **input features** and also **removed duration**.\n",
        "- We implemented **Logistic Regression** and **Decision Tree**, two of the models also studied in the paper.\n",
        "- The paper additionally uses **Neural Networks** and other models.  \n",
        "  In this project, we mention them only as future work.\n",
        "\n",
        "### Suggested Improvements (Future Work)\n",
        "\n",
        "- Perform **hyperparameter tuning**:\n",
        "  - For Logistic Regression (regularization strength, penalty type).\n",
        "  - For Decision Trees (max depth, min samples split, min samples leaf, etc.).\n",
        "- Try additional models:\n",
        "  - **Neural Networks** (as in the original paper).\n",
        "  - Random Forest, Gradient Boosting, etc.\n",
        "- Use more advanced evaluation:\n",
        "  - Cross-validation instead of a single train/test split.\n",
        "  - More marketing metrics:\n",
        "    - **Lift** and **ALIFT** curves.\n",
        "- Perform **feature selection** to simplify the model and possibly improve generalization.\n",
        "\n",
        "---\n",
        "\n",
        "This notebook can now be:\n",
        "- Uploaded to **GitHub** in the `models` folder (or root directory).\n",
        "- Linked with a **README.md** that explains how to run it.\n",
        "- Used as the technical base for your **10–15 minute presentation**."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}