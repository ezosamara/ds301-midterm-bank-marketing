{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvgxup5CZXUaWBf2QIJjDF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezosamara/ds301-midterm-bank-marketing/blob/main/BankMarketing_Midterm_MoatazSamara.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWEWE_nVVirs"
      },
      "outputs": [],
      "source": [
        "import warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Load (uploaded) CSV\n",
        "PATH = \"/content/bank-full.csv\"  # if you renamed or zipped, adjust\n",
        "df = pd.read_csv(PATH, sep=';')\n",
        "print(df.shape)\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "AIoggM8SV1Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map target y: yes/no -> 1/0\n",
        "df['y'] = (df['y'].str.lower() == 'yes').astype(int)\n",
        "\n",
        "# IMPORTANT: drop duration (target leakage per UCI)\n",
        "if 'duration' in df.columns:\n",
        "    df = df.drop(columns=['duration'])\n",
        "\n",
        "# 'pdays' special \"not contacted before\" flag (999 or -1 depending on version)\n",
        "if 'pdays' in df.columns:\n",
        "    never_vals = {999, -1}\n",
        "    df['pdays_never'] = df['pdays'].isin(never_vals).astype(int)\n",
        "\n",
        "print(\"Class balance (1=yes):\", df['y'].mean().round(3))\n",
        "df.describe(include='all').T.head(12)\n"
      ],
      "metadata": {
        "id": "6i_lcpimV4PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "y = df['y'].copy()\n",
        "X = df.drop(columns=['y'])\n",
        "\n",
        "# Identify categorical vs numeric columns\n",
        "cat_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
        "num_cols = [c for c in X.columns if c not in cat_cols]\n",
        "\n",
        "pre = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "        (\"num\", StandardScaler(), num_cols)\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "len(cat_cols), len(num_cols), X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "qkdPorjgV8Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, roc_curve, confusion_matrix, classification_report)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "def fit_grid(pipe, params, name):\n",
        "    gs = GridSearchCV(pipe, params, scoring=\"roc_auc\", cv=cv, n_jobs=-1)\n",
        "    gs.fit(X_train, y_train)\n",
        "    y_pred = gs.predict(X_test)\n",
        "    y_proba = gs.predict_proba(X_test)[:,1] if hasattr(gs, \"predict_proba\") else None\n",
        "    print(f\"\\n{name} — best params:\", gs.best_params_)\n",
        "    print(classification_report(y_test, y_pred, digits=3))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    res = {\n",
        "        \"model\": name,\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
        "        \"roc_auc\": roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
        "    }\n",
        "    return gs, res, y_proba\n"
      ],
      "metadata": {
        "id": "G0dGTkDBV-k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1) Logistic Regression (class_weight helps imbalance)\n",
        "pipe_lr = Pipeline([(\"pre\", pre),\n",
        "                    (\"clf\", LogisticRegression(max_iter=4000, solver='liblinear', class_weight='balanced'))])\n",
        "grid_lr = {\"clf__C\":[0.1,1,10]}\n",
        "gs_lr, res_lr, proba_lr = fit_grid(pipe_lr, grid_lr, \"Logistic Regression\")\n",
        "\n",
        "# 2) KNN (no class_weight in KNN, but distance weights help)\n",
        "pipe_knn = Pipeline([(\"pre\", pre), (\"clf\", KNeighborsClassifier())])\n",
        "grid_knn = {\"clf__n_neighbors\": list(range(5,31,2)),\n",
        "            \"clf__weights\": [\"uniform\",\"distance\"],\n",
        "            \"clf__p\": [1,2]}\n",
        "gs_knn, res_knn, proba_knn = fit_grid(pipe_knn, grid_knn, \"KNN\")\n",
        "\n",
        "# 3) Decision Tree (class_weight helps imbalance)\n",
        "pipe_dt = Pipeline([(\"pre\", pre),\n",
        "                    (\"clf\", DecisionTreeClassifier(random_state=RANDOM_STATE, class_weight='balanced'))])\n",
        "grid_dt = {\"clf__criterion\": [\"gini\",\"entropy\"],\n",
        "           \"clf__max_depth\": [4,6,8,10,12,None],\n",
        "           \"clf__min_samples_leaf\": [1,2,4]}\n",
        "gs_dt, res_dt, proba_dt = fit_grid(pipe_dt, grid_dt, \"Decision Tree\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNjRU1ZJWP6h",
        "outputId": "fec058f7-10f1-4821-e4c4-eec2273e50f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression — best params: {'clf__C': 0.1}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.941     0.765     0.844      9981\n",
            "           1      0.265     0.639     0.375      1322\n",
            "\n",
            "    accuracy                          0.751     11303\n",
            "   macro avg      0.603     0.702     0.610     11303\n",
            "weighted avg      0.862     0.751     0.789     11303\n",
            "\n",
            "Confusion matrix:\n",
            " [[7639 2342]\n",
            " [ 477  845]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC\n",
        "plt.figure(figsize=(7,6))\n",
        "def add_curve(proba, label):\n",
        "    if proba is None: return\n",
        "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
        "    auc = roc_auc_score(y_test, proba)\n",
        "    plt.plot(fpr, tpr, label=f\"{label} (AUC={auc:.3f})\")\n",
        "\n",
        "add_curve(proba_lr, \"Logistic Regression\")\n",
        "add_curve(proba_knn, \"KNN\")\n",
        "add_curve(proba_dt, \"Decision Tree\")\n",
        "\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC — Bank Marketing (Test Set)\"); plt.legend(loc=\"lower right\"); plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Summary table\n",
        "import pandas as pd\n",
        "summary = pd.DataFrame([res_lr, res_knn, res_dt]).set_index(\"model\").sort_values(\"roc_auc\", ascending=False)\n",
        "summary\n"
      ],
      "metadata": {
        "id": "WRetoEG_WSKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations — Moataz Samara\n",
        "- We removed `duration` to avoid leakage (per UCI) and kept a fair setup.\n",
        "- Because the dataset is imbalanced (few “yes”), ROC–AUC is a better main metric; Precision/Recall show trade-offs.\n",
        "- Logistic Regression with class_weight often leads on ROC–AUC (stable with many one-hot features). KNN benefits from distance weighting; DT needs depth/leaves constraints plus class_weight to avoid bias.\n",
        "- Suggested improvements (not required now): threshold tuning for higher recall on “yes”, try class-weights vs. resampling (SMOTE/undersampling), and compare simple ensembles (Random Forest/Gradient Boosting) for robustness.\n"
      ],
      "metadata": {
        "id": "AKCTZloNXRfD"
      }
    }
  ]
}